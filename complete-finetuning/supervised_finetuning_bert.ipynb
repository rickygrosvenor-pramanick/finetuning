{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLZzjW6Vba7XOjAXOYNF/2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rickygrosvenor-pramanick/finetuning/blob/main/complete-finetuning/supervised_finetuning_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLU1lPwGFLJ9",
        "outputId": "c9d6c3d5-8969-47f6-83af-b8339e267336"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers datasets seqeval"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L -o conll2003.zip https://data.deepai.org/conll2003.zip\n",
        "!unzip -q conll2003.zip -d conll2003\n",
        "!ls conll2003"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsDNXL3WIx2n",
        "outputId": "ac85bb09-9c09-4dbd-ec47-c9b9cce8a3ce"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  959k  100  959k    0     0   581k      0  0:00:01  0:00:01 --:--:--  581k\n",
            "metadata  test.txt  train.txt  valid.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    BertTokenizerFast,\n",
        "    BertForTokenClassification,\n",
        "    DataCollatorForTokenClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "from seqeval.metrics import classification_report\n",
        "\n",
        "MODEL_NAME = \"bert-base-uncased\"\n",
        "OUTPUT_DIR = \"./bert-ner\""
      ],
      "metadata": {
        "id": "hC_-3j3oIFh6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "def read_conll(path):\n",
        "    tokens_list, tags_list = [], []\n",
        "    tokens, tags = [], []\n",
        "    with open(path, encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                if tokens:\n",
        "                    tokens_list.append(tokens)\n",
        "                    tags_list.append(tags)\n",
        "                    tokens, tags = [], []\n",
        "            else:\n",
        "                # format: WORD POS CHUNK NER\n",
        "                parts = line.split()\n",
        "                tokens.append(parts[0])\n",
        "                tags.append(parts[-1])\n",
        "        # catch last sentence (if no trailing newline)\n",
        "        if tokens:\n",
        "            tokens_list.append(tokens)\n",
        "            tags_list.append(tags)\n",
        "    return tokens_list, tags_list\n",
        "\n",
        "# point these at your actual Colab paths\n",
        "train_tokens, train_tags = read_conll(\"conll2003/train.txt\")\n",
        "val_tokens,   val_tags   = read_conll(\"conll2003/valid.txt\")\n",
        "test_tokens,  test_tags  = read_conll(\"conll2003/test.txt\")\n",
        "\n",
        "train_ds = Dataset.from_dict({\"tokens\": train_tokens, \"ner_tags\": train_tags})\n",
        "val_ds   = Dataset.from_dict({\"tokens\": val_tokens,   \"ner_tags\": val_tags})\n",
        "test_ds  = Dataset.from_dict({\"tokens\": test_tokens,  \"ner_tags\": test_tags})\n",
        "\n",
        "raw_datasets = DatasetDict({\n",
        "    \"train\": train_ds,\n",
        "    \"validation\": val_ds,\n",
        "    \"test\": test_ds\n",
        "})\n"
      ],
      "metadata": {
        "id": "T74Ht8kyITrX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKTJojkpIYjo",
        "outputId": "0c1b092b-6fec-48c3-c168-17b6db08bcb6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tokens': ['EU',\n",
              "  'rejects',\n",
              "  'German',\n",
              "  'call',\n",
              "  'to',\n",
              "  'boycott',\n",
              "  'British',\n",
              "  'lamb',\n",
              "  '.'],\n",
              " 'ner_tags': ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hp7jmROFSlUd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}